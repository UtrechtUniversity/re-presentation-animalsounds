--- 
format: 
  revealjs:
    theme: themes/uu.scss
    logo: images/UU_logo_2021_EN_RGB.png
    footer: "Parisa Zahedi & Jelle Treep"
---

# Animal Sounds {data-background-color="#FFCD00"}

::: {.r-stack}
Detecting primate vocalizations in a jungle of audio recordings
:::

## Background

::: {.theme-section}
Biodiversity monitoring in tropical rainforests in relation to wood logging certification

<br> 

Bioacoustic monitoring: 

-   is a non-invasive method to monitor biodiversity
-   dense canopy makes visual monitoring difficult

:::

## Background

::: {.theme-section}
Applied Data Science seed grant for interdisciplinary collaboration

<br> 

Team: 

- Researcher biology
- 2 biology students
- Researcher in human speech recognition
- Research Engineers (3x)

:::


## {data-background-image="images/Slide6.jpg"}

## Challenges and objectives
::: {.theme-section-large}
-   Data processing requires automation
-   Machine learning requires labeled data
-   Low vocalization density
-   Training data is not available
-   Noisy environment
:::

## {data-background-image="images/Slide8.jpg"}

## Challenges and objectives
::: {.theme-section}
-   Can we use data from a zoo to train a model, and detect vocalizations in the wild?
-   If so > create a pipeline to automate the process for reuse in other projects
:::

## {data-background-image="images/Slide10.jpg"}

## {data-background-image="images/Slide11.jpg"}

## {data-background-image="images/Slide14.jpg"}

::: {.fragment}
![](images/condensation.png){width=50%}
:::

## Training data

| Species | # vocalizations | example |
|---------|--------------------|---|
| Chimpanzee | 1190 | ![](audio/0209.wav) |
| Guenon |  554 | ![](audio/098.wav) |
| Mandrill | 2717 | ![](audio/1082.wav) |
| Red Capped Mangabey | 584 | ![](audio/0010.wav) |

## {data-background-image="images/Slide16.jpg" background-size="600px"}

## {data-background-image="images/Slide18.jpg"}

## Creating synthetic data

::: {.theme-section}

- "We need more"

- Combine vocalizations with jungle noise

- Dampen the vocalizations to simulate distance

  - 0 dB
  - -3.3 dB
  - -6.6 dB
  - -10 dB

- For each segment, 4 new segments are created

:::

## Training and testing classifiers

::: {.theme-section-larger}
<br>
How to test the classifiers?
:::

## {data-background-image="images/Slide23.jpg"}

## {data-background-image="images/Slide24.jpg"}

## Classical machine learning

::: {.theme-section}
Feature extraction inspired by human speech recognition

Feature importance
Feature selection
SVM
:::


## Project Overview

::: {.theme-section}
- Preprocessing
  - Condensation
  - Raven to wav 
  - Generate synthetic data

- Feature extractions
  - audio features
  - MFCC ...

- Classification
    - SVM
    - Deep learning models


:::


## Deep learning Models

::: {.theme-section}
<div style="font-size: 0.8em;">
Convolutional Neural Networks (CNN)

- Convolutional layer
  - Detects features e.g., edges, textures, by applying filters
- Pooling layer: 
  - Reduces the dimensionality of feature maps 
- Fully Connected layer
  - maps the features to the final output 
</div>
<div style="text-align: center;">
![](images/convolution.png)
</div>
:::

## How does CNN work?
::: {.theme-section}
- Input: Raw data, often an image (e.g., 32x32 RGB image).
- 1: Apply convolutional filters to detect features like edges, corners, textures.
- 2: Use pooling to reduce the size of feature maps (e.g., from 32x32 to 16x16).
- 3: Pass the output through fully connected layers for classification.
<div style="text-align: center;">  
![](images/cnn.png)
</div>
:::

## How doe we change audio to image?
::: {.theme-section}
<b>Spectrogram</b>
- represents the intensity of different frequencies as they change over time, typically using a color map 

<b>Log-mel-spectrogram </b> a variation of the standard spectrogram that applies a filter bank and a log function on top of it. 

-	making quieter sounds more detectable.

-	Aligns the representation with human auditory perception

-	Normalizes the features

<div style="text-align: center;">  
![](images/logmel.png)
</div>
:::

## Model Architecture - Derived from PANNs
::: {.theme-section}

PANNs: Large-Scale Pretrained Audio Neural Networks for Audio Pattern Recognition

- designed for audio event detection and classification

- a combination of convolutional blocks and pooling operations 

<div style="text-align: center;">  
![CNN10 Architecture](images/cnn10.png)
</div>
:::


## Training details

::: {.theme-section}

:::

## Results

::: {.theme-section}

:::

## Challenges & Learning points

::: {.theme-section}


- Collaboration with ML audio expert
- Involvement researcher
- Data management
- Code management (Matlab scripts, repoâ€™s with playground folders, no real git workflow, documentation, package from early stage)
:::

## Future work

::: {.theme-section}

:::

# {data-background-color="#FFCD00"}

![](images/UU_logo_2021_EN_RGB_payoff.png)