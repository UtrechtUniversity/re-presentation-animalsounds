--- 
format: 
  revealjs:
    theme: themes/uu.scss
    logo: images/UU_logo_2021_EN_RGB.png
    footer: "Parisa Zahedi & Jelle Treep"
---

# Animal Sounds {data-background-color="#FFCD00"}

::: {.r-stack}
Detecting primate vocalizations in a jungle of audio recordings
:::

## Background

::: {.theme-section}
Biodiversity monitoring in tropical rainforests in relation to wood logging certification

<br> 

Bioacoustic monitoring: 

-   is a non-invasive method to monitor biodiversity
-   dense canopy makes visual monitoring difficult

:::

## Background

::: {.theme-section}
Applied Data Science seed grant for interdisciplinary collaboration

<br> 

Team: 

- Researcher biology
- 2 biology students
- Researcher in human speech recognition
- Research Engineers (3x)

:::


## {data-background-image="images/Slide6.jpg"}

## Challenges and objectives
::: {.theme-section-large}
-   Data processing requires automation
-   Machine learning requires labeled data
-   Low vocalization density
-   Training data is not available
-   Noisy environment
:::

## {data-background-image="images/Slide8.jpg"}

## Challenges and objectives
::: {.theme-section}
-   Can we use data from a zoo to train a model, and detect vocalizations in the wild?
-   If so > create a pipeline to automate the process for reuse in other projects
:::

## {data-background-image="images/Slide10.jpg"}

## {data-background-image="images/Slide11.jpg"}

## {data-background-image="images/Slide14.jpg"}

::: {.fragment}
![](images/condensation.png){width=50%}
:::

## Training data

| Species | # vocalizations | example |
|---------|--------------------|---|
| Chimpanzee | 1190 | ![](audio/0209.wav) |
| Guenon |  554 | ![](audio/098.wav) |
| Mandrill | 2717 | ![](audio/1082.wav) |
| Red Capped Mangabey | 584 | ![](audio/0010.wav) |

## {data-background-image="images/Slide16.jpg" background-size="600px"}

## {data-background-image="images/Slide18.jpg"}

## Creating synthetic data

::: {.theme-section}

- "We need more"

- Combine vocalizations with jungle noise

- Dampen the vocalizations to simulate distance

  - 0 dB
  - -3.3 dB
  - -6.6 dB
  - -10 dB

- For each segment, 4 new segments are created

:::

## Training and testing classifiers

::: {.theme-section-larger}
<br>
How to test the classifiers?
:::

## {data-background-image="images/Slide23.jpg"}

## {data-background-image="images/Slide24.jpg"}

## Classical machine learning

::: {.theme-section}
Feature extraction inspired by human speech recognition

Feature importance
Feature selection
SVM
:::


## Project Overview

::: {.theme-section}
- Preprocessing
  - Condensation
  - Raven to wav 
  - Generate synthetic data

- Feature extractions
  - audio features
  - MFCC ...

- Classification
    - SVM
    - Deep learning models


:::


## Deep learning Models

::: {.theme-section}

:::

## Training details

::: {.theme-section}

:::

## Results

::: {.theme-section}

:::

## Challenges & Learning points

::: {.theme-section}

:::

## Future work

::: {.theme-section}

:::
# {data-background-color="#FFCD00"}

![](images/UU_logo_2021_EN_RGB_payoff.png)
